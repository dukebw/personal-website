<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <meta content="width=device-width,initial-scale=1" name="viewport">
    <meta content="description" name="description">
    <meta name="google" content="notranslate" />
    <meta content="Mashup templates have been developped by Orson.io team" name="author">

    <!-- Disable tap highlight on IE -->
    <meta name="msapplication-tap-highlight" content="no">

    <link rel="apple-touch-icon" sizes="180x180" href="./assets/apple-icon-180x180.png">
    <link href="./assets/favicon.ico" rel="icon">

    <title>Brendan Duke</title>

    <link href="./main.d8e0d294.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <style>
        .research-preview-image {
            padding: 2.5%;
            width: 25%;
            vertical-align: middle;
            min-width: 120px;
        }

        .research-description {
            padding: 2.5%;
            width: 75%;
            vertical-align: middle;
        }
    </style>
</head>

<body class="">

    <!-- Add your content of header -->
    <div class="background-color-layer" style="background-image: url('assets/images/hank-wallpaper.jpg')"></div>
    <main class="content-wrapper">
        <header class="white-text-container section-container">
            <div class="text-center">
                <h1>Brendan Duke</h1>
                <p>Machine Learning Researcher</p>
                <p>
                <div class="container">
                    <div class="row">
                        <a class="fa-icon fa-icon-2x" href="https://www.facebook.com/brendan.duke.39" title="">
                            <i class="fa fa-facebook"></i>
                        </a>
                        <a class="fa-icon fa-icon-2x" href="https://twitter.com/BrendanDuke6" title="">
                            <i class="fa fa-twitter"></i>
                        </a>
                        <a class="fa-icon fa-icon-2x" href="https://scholar.google.com/citations?user=Gd2IGrEAAAAJ" title="">
                            <i class="ai ai-google-scholar-square"></i>
                        </a>
                        <a class="fa-icon fa-icon-2x" href="https://linkedin.com/in/brendan-duke-b3236095" title="">
                            <i class="fa fa-linkedin"></i>
                        </a>
                        <a class="fa-icon fa-icon-2x" href="https://github.com/dukebw" title="">
                            <i class="fa fa-github"></i>
                        </a>
                    </div>
                </div>
                </p>
            </div>
        </header>



        <!-- Add your site or app content here -->

        <div class="container">
            <div class="row">
                <div class="col-xs-12">

                    <div class="card">
                        <div class="card-block">
                            <h2>About me</h2>
                            <div class="row">
                                <div class="col-md-4">
                                    <p><img src="./assets/images/brendan1.jpg" class="img-responsive" alt=""></p>
                                </div>
                                <div class="col-md-8">

                                    <p>I am a PhD student at the <a href="https://www.utoronto.ca/">University of Toronto</a> advised by <a href="http://p.arh.am">Parham Aarabi</a>, and a Research Scientist Team Lead at <a href="https://modiface.com">ModiFace, Inc</a>.
                                        My research interests include machine learning, deep learning, and computer vision.
                                        At ModiFace I apply deep learning to the beauty tech space to create augmented reality (AR) virtual experiences.
                                    </p>
                                    <p>I had the pleasure of completing my M.A.Sc. at the University of Guelph advised by <a href="https://www.gwtaylor.ca/">Graham Taylor</a> in the <a href="https://www.gwtaylor.ca/">Machine Learning Research Group (MLRG)</a>.
                                        My master's thesis focused on <a href="https://atrium.lib.uoguelph.ca/xmlui/bitstream/handle/10214/21303/Duke_Brendan_202009_MASc.pdf?sequence=6">attention and fusion operators in computer vision</a>.
                                    </p>
                                    <p>
                                        Previous to that I worked at AMD writing firmware for the <a href="https://www.amd.com/en/technologies/pro-security">AMD Secure Processor</a>.
                                    </p>

                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="card">
                        <div class="card-block">
                            <h2>Research</h2>
                            <div class="row">
                                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">





                                    <tbody>
                                        <tr>

                                            <td class="research-preview-image">
                                                <img src="./assets/images/sstvos.png" alt="SSTVOS Architecture" style="width:auto; height:auto; max-width:100%;">
                                            </td>
                                            <td class="research-description">
                                                <h3>SSTVOS: Sparse Spatiotemporal Transformers for Video Object Segmentation</h3>
                                                <br>
                                                <strong>Brendan Duke</strong>, Abdalla Ahmed, Christian Wolf, Parham Aarabi, Graham W. Taylor

                                                <br>
                                                <strong>CVPR 2021 Oral</strong> <em>(4.3% acceptance rate)</em>
                                                <br>
                                                <a href="https://arxiv.org/abs/2101.08833">paper</a> / <a href="https://github.com/dukebw/SSTVOS">code</a>
                                                <p>We introduce a Transformer-based approach to video object segmentation (VOS).
                                                    Our method, called Sparse Spatiotemporal Transformers (SST), extracts per-pixel representations for each object in a video using sparse attention over spatiotemporal features.
                                                </p>
                                            </td>
                                        </tr>

                                        <tr>

                                            <td class="research-preview-image">
                                                <img src="./assets/images/loho.png" alt="LOHO Preview" style="width:auto; height:auto; max-width:100%;">
                                            </td>
                                            <td class="research-description">
                                                <h3>LOHO: Latent Optimization of Hairstyles via Orthogonalization</h3>
                                                <br>
                                                Rohit Saha, <strong>Brendan Duke</strong>, Florian Shkurti, Graham W. Taylor, Parham Aarabi

                                                <br>
                                                <strong>CVPR 2021</strong>
                                                <br>
                                                <a href="https://arxiv.org/abs/2103.03891">paper</a> / <a href="https://github.com/dukebw/LOHO">code</a>
                                                <p>We propose Latent Optimization of Hairstyles via Orthogonalization (LOHO), an optimization-based approach using GAN inversion to infill missing hair structure details in latent space during hairstyle transfer.
                                                    Using LOHO for latent space manipulation, users can synthesize novel photorealistic images by manipulating hair attributes either individually or jointly, transferring the desired attributes from reference hairstyles.
                                                </p>
                                            </td>
                                        </tr>
                                </table>
                            </div>
                        </div>
                    </div>
    </main>
    <footer class="footer-container white-text-container text-center">
        <div class="container">
            <div class="row">
                <div class="col-xs-12">
                    <p><img src="./assets/images/mashup-icon.svg" alt=""></p>
                </div>
            </div>
        </div>
    </footer>

    <script>
        document.addEventListener("DOMContentLoaded", function(event) {
            scrollRevelation('.card');
        });
    </script>
    <!-- Google Analytics: change UA-XXXXX-X to be your site's ID 

<script>
  (function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
      (i[r].q = i[r].q || []).push(arguments)
    }, i[r].l = 1 * new Date(); a = s.createElement(o),
      m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
  })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
  ga('create', 'UA-XXXXX-X', 'auto');
  ga('send', 'pageview');
</script>

-->
    <script type="text/javascript" src="./main.bc58148c.js"></script>
</body>

</html>
