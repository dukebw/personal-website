<!DOCTYPE html>
<html lang="en-US">
  <head>
	<meta name="generator" content="Hugo 0.127.0">
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta http-equiv="cache-control" content="max-age=0" />
    <meta http-equiv="cache-control" content="no-cache" />
    <meta http-equiv="expires" content="0" />
    <meta http-equiv="expires" content="Tue, 01 Jan 1980 1:00:00 GMT" />
    <meta http-equiv="pragma" content="no-cache" />

    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"}>
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <meta name="theme-color" media="(prefers-color-scheme: light)" content="#ffffff" />
    <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1b" />

    <meta name="description" content="Brendan Duke">

    <link rel="alternate" type="application/rss+xml" href="https://brendanduke.ca/index.xml" title="Brendan Duke" />
    
        <title>Brendan Duke</title>
    

    
    <style>
        :root {
          --background: #ffffff;
        }
        @media (prefers-color-scheme: dark) {
          :root {
            --background: #1b1b1b;
          }
        }
        html {
            background-color: var(--background);
        }
        body {
            background-color: var(--background);
        }
    </style>

    
    <link rel="stylesheet" type="text/css" href="/style.min.2a420bbab4c0a4454a1165e5c5e6fc927800e254a6ffdc266cefe0a1bdd3d1eb.css" media="all">
  </head>

  <body>
        
        <nav>
          <ul class="menu">
            
                <li><a tabindex="-1" class="menu-link" href="/"><u>H</u>ome</a></li>
            
                <li><a tabindex="-1" class="menu-link" href="/tags"><u>T</u>ags</a></li>
            
          </ul>
        </nav>
        


<div class="home-content"><div class="centered-content">
<h1 id="brendan-duke">Brendan Duke</h1>
<p>Machine learning engineer</p>
<div class="container">
    <div class="row">
        <a class="fa-icon fa-icon-2x" href="https://www.facebook.com/brendan.duke.39" title="">
            <i class="fa-brands fa-facebook"></i>
        </a>
        <a class="fa-icon fa-icon-2x" href="https://techhub.social/@brendanduke" title="">
            <i class="fa-brands fa-mastodon"></i>
        </a>
        <a class="fa-icon fa-icon-2x" href="https://scholar.google.com/citations?user=Gd2IGrEAAAAJ" title="">
            <i class="ai ai-google-scholar-square"></i>
        </a>
        <a class="fa-icon fa-icon-2x" href="https://linkedin.com/in/brendan-duke-b3236095" title="">
            <i class="fa-brands fa-linkedin"></i>
        </a>
        <a class="fa-icon fa-icon-2x" href="https://github.com/dukebw" title="">
            <i class="fa-brands fa-github"></i>
        </a>
    </div>
</div>
</div>
<h2 id="about-me">About me</h2>
<div class="row">
<div class="image-grid">
    <img src="./assets/images/brendan1.jpg" alt="Brendan 1" />
</div>
<div>
I am a software engineer keenly interested in machine learning systems.
<p>I completed my PhD under the guidance of <a href="https://www.ece.utoronto.ca/people/aarabi-p/"  target="_blank" rel="noreferrer nofollow">Parham Aarabi</a>
.
I had the pleasure of completing my M.A.Sc. at the University of Guelph advised by <a href="https://www.gwtaylor.ca/"  target="_blank" rel="noreferrer nofollow">Graham Taylor</a>
 in the <a href="https://www.gwtaylor.ca/"  target="_blank" rel="noreferrer nofollow">Machine Learning Research Group (MLRG)</a>
.
My master&rsquo;s thesis focused on <a href="https://atrium.lib.uoguelph.ca/xmlui/bitstream/handle/10214/21303/Duke_Brendan_202009_MASc.pdf?sequence=6"  target="_blank" rel="noreferrer nofollow">attention and fusion operators in computer vision</a>

and my research interests include machine learning, deep learning, and computer
vision.</p>
<p>Previously in my career, I was a Machine Learning Team Lead at
<a href="https://modiface.com"  target="_blank" rel="noreferrer nofollow">ModiFace, Inc</a>
 where I applied deep learning to the
beauty tech space to create augmented reality (AR) virtual experiences.
And prior to that I worked at AMD writing firmware for the <a href="https://www.amd.com/en/technologies/pro-security"  target="_blank" rel="noreferrer nofollow">AMD Secure Processor</a>
.</p>
</div>
</div>
<h2 id="research">Research</h2>
<div class="row">
<div class="image-grid">
  <img src="./assets/images/sstvos.png" />
</div>
<div>
<h3 id="sstvos-sparse-spatiotemporal-transformers-for-video-object-segmentation">SSTVOS: Sparse Spatiotemporal Transformers for Video Object Segmentation</h3>
<p><strong>Brendan Duke</strong>, Abdalla Ahmed, Christian Wolf, Parham Aarabi, Graham W. Taylor</p>
<p><strong>CVPR 2021 Oral</strong> <em>(4.3% acceptance rate)</em></p>
<p><a href="https://arxiv.org/abs/2101.08833"  target="_blank" rel="noreferrer nofollow">paper</a>
 / <a href="https://github.com/dukebw/SSTVOS"  target="_blank" rel="noreferrer nofollow">code</a>
</p>
<p>We introduce a Transformer-based approach to video object segmentation (VOS).
Our method, called Sparse Spatiotemporal Transformers (SST), extracts per-pixel representations for each object in a video using sparse attention over spatiotemporal features.</p>
</div>
</div>
<div class="row">
<div class="image-grid">
  <img src="./assets/images/loho.png" />
</div>
<div>
<h3 id="loho-latent-optimization-of-hairstyles-via-orthogonalization">LOHO: Latent Optimization of Hairstyles via Orthogonalization</h3>
<p>Rohit Saha, <strong>Brendan Duke</strong>, Florian Shkurti, Graham W. Taylor, Parham Aarabi</p>
<p><strong>CVPR 2021</strong></p>
<p><a href="https://arxiv.org/abs/2103.03891"  target="_blank" rel="noreferrer nofollow">paper</a>
 / <a href="https://github.com/dukebw/LOHO"  target="_blank" rel="noreferrer nofollow">code</a>
</p>
<p>We propose Latent Optimization of Hairstyles via Orthogonalization (LOHO), an optimization-based approach using GAN inversion to infill missing hair structure details in latent space during hairstyle transfer.
Using LOHO for latent space manipulation, users can synthesize novel photorealistic images by manipulating hair attributes either individually or jointly, transferring the desired attributes from reference
hairstyles.</p>
</div>
</div>
<div class="row">
<div class="image-grid">
  <img src="./assets/images/masc-thesis.png" />
</div>
<div>
<h3 id="attention-and-fusion-of-deep-representations-for-computer-vision">Attention and Fusion of Deep Representations for Computer Vision</h3>
<p><strong>Brendan Duke</strong></p>
<p><strong>M.A.Sc. Thesis</strong></p>
<p><a href="https://atrium.lib.uoguelph.ca/xmlui/bitstream/handle/10214/21303/Duke_Brendan_202009_MASc.pdf?sequence=6"  target="_blank" rel="noreferrer nofollow">thesis</a>
</p>
<p>In my master&rsquo;s work I investigated attention and multimodal fusion operators.
I applied these operators to visual question answering (VQA) and video object segmentation (VOS).</p>
</div>
</div>
<div class="row">
<div class="image-grid">
  <img src="./assets/images/nail-polish-try-on.png" />
</div>
<div>
<h3 id="nail-polish-try-on-realtime-semantic-segmentation-of-small-objects-for-native-and-browser-smartphone-ar-applications">Nail Polish Try-On: Realtime Semantic Segmentation of Small Objects for Native and Browser Smartphone AR Applications</h3>
<p><strong>Brendan Duke</strong>, Abdalla Ahmed, Edmund Phung, Irina Kezele, Parham Aarabi</p>
<p><strong>CVPR 2019 CV for AR/VR Workshop</strong></p>
<p><a href="https://arxiv.org/abs/1906.02222"  target="_blank" rel="noreferrer nofollow">paper</a>
</p>
<p>We provide a system for semantic segmentation of small objects that enables nail polish try-on AR applications to run client-side in realtime in native and web mobile applications.
This work powers a <a href="https://www.retaildive.com/news/essie-modiface-debut-ar-nail-polish-try-on-tool/595453/"  target="_blank" rel="noreferrer nofollow">nail polish brand&rsquo;s virtual try-on experience</a>
.</p>
</div>
</div>
<div class="row">
<div class="image-grid">
  <img src="./assets/images/tiny-cnn.png" />
</div>
<div>
<h3 id="lightweight-real-time-makeup-try-on-in-mobile-browsers-with-tiny-cnn-models-for-facial-tracking">Lightweight Real-time Makeup Try-on in Mobile Browsers with Tiny CNN Models for Facial Tracking</h3>
<p>Tianxing Li, Zhi Yu, Edmund Phung, <strong>Brendan Duke</strong>, Irina Kezele, Parham Aarabi</p>
<p><strong>CVPR 2019 CV for AR/VR Workshop (Oral)</strong></p>
<p><a href="https://arxiv.org/abs/1906.02260"  target="_blank" rel="noreferrer nofollow">paper</a>
</p>
<p>We design small models for high accuracy facial alignment.
The models we propose make use of light CNN architectures adapted to the facial alignment problem for accurate two-stage prediction of facial landmark coordinates from low-resolution output heatmaps.</p>
</div>
</div>
<div class="row">
<div class="image-grid">
  <img src="./assets/images/generalized-hadamard.png" />
</div>
<div>
<h3 id="generalized-hadamard-product-fusion-operators-for-visual-question-answering">Generalized Hadamard-Product Fusion Operators for Visual Question Answering</h3>
<p><strong>Brendan Duke</strong>, Graham W. Taylor</p>
<p><strong>Computer and Robot Vision (CRV) 2018 (Best Paper Award)</strong></p>
<p><a href="https://arxiv.org/abs/1803.09374"  target="_blank" rel="noreferrer nofollow">paper</a>
</p>
<p>We propose a generalized class of multimodal fusion operators for the task of visual question answering (VQA).
We identify generalizations of existing multimodal fusion operators based on the Hadamard product, and show that specific non-trivial instantiations of this generalized fusion operator exhibit superior
performance in terms of OpenEnded accuracy on the VQA task.</p>
</div>
</div>
</div>


    
    <form id="search"
    action='https://brendanduke.ca/' method="get">
    <label hidden for="search-input">Search site</label>
    <input tabindex="-1" type="text" id="search-input" name="query"
    placeholder="search [i] ...">
    
</form>


    <ul id="results"></ul>

    


<br>

<footer>

<script defer>
  document.addEventListener("keydown", function (e) {
    if (document.activeElement.isContentEditable) {
      return false;
    }
    if (document.activeElement.tagName == "INPUT") {
      return false;
    }
    if (e.altKey || e.ctrlKey || e.shiftKey) {
      return false;
    }
    var key = e.key;
    if (key === "h") {
      e.preventDefault();
      e.stopPropagation();
      window.location.href = "/";
    } else if (key === "t") {
      e.preventDefault();
      e.stopPropagation();
      window.location.href = `https://${location.hostname}/tags`;
    } else if (key === "i") {
      e.preventDefault();
      e.stopPropagation();
      const inputs = document.querySelectorAll("input");
      for (let i = 0; i < inputs.length; i++) {
        if (inputs[i].offsetParent !== null) {
          inputs[i].selectionStart = inputs[i].selectionEnd =
            inputs[i].value.length;
          inputs[i].focus();
          break;
        }
      }
    }
    return false;
  });
</script>


<script defer>
  function throttle(fn, wait) {
    var time = Date.now();
    return function () {
      var now = Date.now()
      if (time + wait - now < 0) {
        fn();
        time = now;
      }
    };
  }

  function scrollHandler() {
    const anchors = Array.from(document.querySelectorAll("body h2, body h3"));

    function scrollCallback() {
      var scrollTop = window.pageYOffset || document.documentElement.scrollTop;

      
      for (var i = 0; i < anchors.length; i++) {
        var anchorId = anchors[i].getAttribute("id");
        var link = document.querySelector(
          'nav ul li a[href="#' + anchorId + '"]',
        );
        if (link) {
          link.classList.remove("active-toc");
        }
      }

      
      for (var i = anchors.length - 1; i >= 0; i--) {
        var offsetTop = anchors[i].offsetTop;
        if (scrollTop > offsetTop - 75) {
          var anchorId = anchors[i].getAttribute("id");
          var link = document.querySelector(
            'nav ul li a[href="#' + anchorId + '"]',
          );
          if (link) {
            link.classList.add("active-toc");
            break;
          }
        }
      }
    }

    window.addEventListener(
      "scroll",
      throttle(scrollCallback, 300),
    );
  }
  setTimeout(scrollHandler, 100);
</script>

<script defer>
  function addCopyButtonToCodeBlocks() {
    
    const codeBlocks = document.querySelectorAll('code[class^="language-"]');

    codeBlocks.forEach((codeBlock) => {
      const copyButton = document.createElement("button");
      copyButton.classList.add("copy-code-button");
      copyButton.innerHTML = "copy";

      
      copyButton.addEventListener("click", () => {
        
        const elements = codeBlock.querySelectorAll(".cl");
        let codeToCopy = "";
        elements.forEach((element) => {
          codeToCopy += element.innerText;
        });
        navigator.clipboard.writeText(codeToCopy);

        
        copyButton.innerHTML = "copied!";
        setTimeout(() => {
          copyButton.innerHTML = "copy";
        }, 1500);
      });

      
      codeBlock.parentNode.before(copyButton);
    });
  }
  setTimeout(function () {
    addCopyButtonToCodeBlocks();
  }, 100);
</script>

<script>
window.store = {
    
    "https:\/\/brendanduke.ca\/": {
        "title": "Brendan Duke",
        "tags": [],
        "content": " Brendan Duke Machine learning engineer\nAbout me I am a software engineer keenly interested in machine learning systems. I completed my PhD under the guidance of Parham Aarabi . I had the pleasure of completing my M.A.Sc. at the University of Guelph advised by Graham Taylor in the Machine Learning Research Group (MLRG) . My master\u0026rsquo;s thesis focused on attention and fusion operators in computer vision and my research interests include machine learning, deep learning, and computer vision.\nPreviously in my career, I was a Machine Learning Team Lead at ModiFace, Inc where I applied deep learning to the beauty tech space to create augmented reality (AR) virtual experiences. And prior to that I worked at AMD writing firmware for the AMD Secure Processor .\nResearch SSTVOS: Sparse Spatiotemporal Transformers for Video Object Segmentation Brendan Duke, Abdalla Ahmed, Christian Wolf, Parham Aarabi, Graham W. Taylor\nCVPR 2021 Oral (4.3% acceptance rate)\npaper / code We introduce a Transformer-based approach to video object segmentation (VOS). Our method, called Sparse Spatiotemporal Transformers (SST), extracts per-pixel representations for each object in a video using sparse attention over spatiotemporal features.\nLOHO: Latent Optimization of Hairstyles via Orthogonalization Rohit Saha, Brendan Duke, Florian Shkurti, Graham W. Taylor, Parham Aarabi\nCVPR 2021\npaper / code We propose Latent Optimization of Hairstyles via Orthogonalization (LOHO), an optimization-based approach using GAN inversion to infill missing hair structure details in latent space during hairstyle transfer. Using LOHO for latent space manipulation, users can synthesize novel photorealistic images by manipulating hair attributes either individually or jointly, transferring the desired attributes from reference hairstyles.\nAttention and Fusion of Deep Representations for Computer Vision Brendan Duke\nM.A.Sc. Thesis\nthesis In my master\u0026rsquo;s work I investigated attention and multimodal fusion operators. I applied these operators to visual question answering (VQA) and video object segmentation (VOS).\nNail Polish Try-On: Realtime Semantic Segmentation of Small Objects for Native and Browser Smartphone AR Applications Brendan Duke, Abdalla Ahmed, Edmund Phung, Irina Kezele, Parham Aarabi\nCVPR 2019 CV for AR/VR Workshop\npaper We provide a system for semantic segmentation of small objects that enables nail polish try-on AR applications to run client-side in realtime in native and web mobile applications. This work powers a nail polish brand\u0026rsquo;s virtual try-on experience .\nLightweight Real-time Makeup Try-on in Mobile Browsers with Tiny CNN Models for Facial Tracking Tianxing Li, Zhi Yu, Edmund Phung, Brendan Duke, Irina Kezele, Parham Aarabi\nCVPR 2019 CV for AR/VR Workshop (Oral)\npaper We design small models for high accuracy facial alignment. The models we propose make use of light CNN architectures adapted to the facial alignment problem for accurate two-stage prediction of facial landmark coordinates from low-resolution output heatmaps.\nGeneralized Hadamard-Product Fusion Operators for Visual Question Answering Brendan Duke, Graham W. Taylor\nComputer and Robot Vision (CRV) 2018 (Best Paper Award)\npaper We propose a generalized class of multimodal fusion operators for the task of visual question answering (VQA). We identify generalizations of existing multimodal fusion operators based on the Hadamard product, and show that specific non-trivial instantiations of this generalized fusion operator exhibit superior performance in terms of OpenEnded accuracy on the VQA task.\n", 
        "url": "https:\/\/brendanduke.ca\/"
    },
    
    "https:\/\/brendanduke.ca\/categories\/": {
        "title": "Categories",
        "tags": [],
        "content": "", 
        "url": "https:\/\/brendanduke.ca\/categories\/"
    },
    
    "https:\/\/brendanduke.ca\/tags\/": {
        "title": "Tags",
        "tags": [],
        "content": "", 
        "url": "https:\/\/brendanduke.ca\/tags\/"
    },
    
}
</script>
<script defer src="/js/lunr.js"></script>
<script defer src="/js/search.js"></script>

</footer>

</body>
</html>

